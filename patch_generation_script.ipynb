{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":["import tensorflow as tf\n","import pandas as pd\n","import os\n","from matplotlib import pyplot as plt\n","from tqdm import tqdm\n","import numpy as np\n","import gc"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Reading the dataset\n","\n","filenames_inp=pd.DataFrame({\"file_names\":os.listdir(\"../input/massachusetts-roads-dataset/road_segmentation_ideal/training/input\")})\n","filenames_output=pd.DataFrame({\"file_names\":os.listdir(\"../input/massachusetts-roads-dataset/road_segmentation_ideal/training/output\")})\n","filenames=filenames_inp.loc[filenames_inp.file_names.isin(filenames_output[\"file_names\"]),:]"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Reading the dataset\n","\n","val_filenames_inp=pd.DataFrame({\"file_names\":os.listdir(\"../input/massachusetts-roads-dataset/road_segmentation_ideal/testing/input\")})\n","val_filenames_output=pd.DataFrame({\"file_names\":os.listdir(\"../input/massachusetts-roads-dataset/road_segmentation_ideal/testing/output\")})\n","val_filenames=val_filenames_inp.loc[val_filenames_inp.file_names.isin(filenames_output[\"file_names\"]),:]"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Creating the dataset\n","NUM_PARALLEL_CALLS_DS=os.cpu_count()\n","\n","\n","def get_image_data(image_name):\n","#     with open('../input/massachusetts-roads-dataset/road_segmentation_ideal/training/input/' + image_name, \"rb\") as local_file: \n","#         img = local_file.read()\n","    img = tf.io.read_file('../input/massachusetts-roads-dataset/road_segmentation_ideal/training/input/' + image_name)\n","    \n","#     with open('../input/massachusetts-roads-dataset/road_segmentation_ideal/training/output/' + image_name, \"rb\") as local_file: \n","#         msk = local_file.read()\n","    \n","    msk = tf.io.read_file('../input/massachusetts-roads-dataset/road_segmentation_ideal/training/output/' + image_name)\n","    return tf.cast(tf.image.decode_png(img),tf.int32),tf.cast(tf.image.decode_png(msk),tf.int32),image_name\n","\n","with tf.device('/cpu:0'):\n","    train_data=tf.data.Dataset.from_tensor_slices(filenames['file_names']).map(get_image_data,num_parallel_calls=NUM_PARALLEL_CALLS_DS).batch(10)\n","    validation_data=tf.data.Dataset.from_tensor_slices(val_filenames['file_names']).map(get_image_data,num_parallel_calls=NUM_PARALLEL_CALLS_DS).batch(10)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir train\n","!mkdir train/images\n","!mkdir train/output\n","\n","!mkdir test\n","!mkdir test/images\n","!mkdir test/output"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_csv_lst=[]\n","\n","for imgs in tqdm(train_data):\n","    \n","    patches_img=tf.image.extract_patches(images=imgs[0],\n","                               sizes=[1, 512, 512, 1],\n","                               strides=[1, 493, 493, 1],\n","                               rates=[1, 1, 1, 1],\n","                               padding='VALID')\n","    \n","    patches_mask=tf.image.extract_patches(images=imgs[1],\n","                               sizes=[1, 512, 512, 1],\n","                               strides=[1, 493, 493, 1],\n","                               rates=[1, 1, 1, 1],\n","                               padding='VALID')\n","    \n","    \n","    def save_images_at_row(path,flnm,patch_lst,rw,channels=3):\n","        filename=flnm.decode('utf8').split('.')[0]        \n","        np.save(path + filename  +'_'+ str(rw) + '_' + str(0) + '.npy',np.reshape(patch_lst[rw,0,:].numpy(),(512,512,channels)),allow_pickle=True)        \n","        np.save(path + filename +'_' + str(rw) + '_' + str(1) + '.npy',np.reshape(patch_lst[rw,1,:].numpy(),(512,512,channels)),allow_pickle=True)\n","        np.save(path + filename  +'_' + str(rw) + '_' + str(2) + '.npy',np.reshape(patch_lst[rw,2,:].numpy(),(512,512,channels)),allow_pickle=True)\n","        \n","        \n","    for k,flnm in enumerate(imgs[2].numpy().tolist()):                \n","        for u in range(0,3):\n","            save_images_at_row(\"train/images/\",flnm,patches_img[k,:,:,:],u,channels=3)       \n","            save_images_at_row(\"train/output/\",flnm,patches_mask[k,:,:,:],u,channels=1)   \n","    gc.collect()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(np.load('./train/images/img-542_0_1.npy',allow_pickle=True))"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(np.load('./train/output/img-542_0_1.npy',allow_pickle=True))"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for imgs in tqdm(validation_data):\n","    \n","    patches_img=tf.image.extract_patches(images=imgs[0],\n","                               sizes=[1, 512, 512, 1],\n","                               strides=[1, 493, 493, 1],\n","                               rates=[1, 1, 1, 1],\n","                               padding='VALID')\n","    \n","    patches_mask=tf.image.extract_patches(images=imgs[1],\n","                               sizes=[1, 512, 512, 1],\n","                               strides=[1, 493, 493, 1],\n","                               rates=[1, 1, 1, 1],\n","                               padding='VALID')\n","    \n","    \n","    def save_images_at_row(path,flnm,patch_lst,rw,channels=3):\n","        filename=flnm.decode('utf8').split('.')[0]        \n","        np.save(path + filename  +'_'+ str(rw) + '_' + str(0) + '.npy',np.reshape(patch_lst[rw,0,:].numpy(),(512,512,channels)),allow_pickle=True)\n","        np.save(path + filename +'_' + str(rw) + '_' + str(1) + '.npy',np.reshape(patch_lst[rw,1,:].numpy(),(512,512,channels)),allow_pickle=True)\n","        np.save(path + filename  +'_' + str(rw) + '_' + str(2) + '.npy',np.reshape(patch_lst[rw,2,:].numpy(),(512,512,channels)),allow_pickle=True)\n","    \n","    for k,flnm in enumerate(imgs[2].numpy().tolist()):                \n","        for u in range(0,3):\n","            save_images_at_row(\"test/images/\",flnm,patches_img[k,:,:,:],u,channels=3)       \n","            save_images_at_row(\"test/output/\",flnm,patches_mask[k,:,:,:],u,channels=1)        "],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def plt_img_at_idx(k,i,j):\n","#     fig, (ax1, ax2) = plt.subplots(1, 2)\n","#     ax1.imshow(tf.reshape(patches_img[k,i,j,:],(512,512,3)))\n","#     ax2.imshow(tf.reshape(patches_mask[k,i,j,:],(512,512,1)))\n","    \n","# def merge_and_plot(k):\n","#     fin_img=np.zeros((1536,1536,3))\n","#     fin_img[0:512,0:512,3]=tf.reshape(patches[k,0,0,:],(512,512,3))\n","#     fin_img[512:512,0:512,3]=tf.reshape(patches[k,0,1,:],(512,512,3))\n","#     fin_img[0:512,0:512,3]=tf.reshape(patches[k,1,0,:],(512,512,3))\n","#     fin_img[0:512,0:512,3]=tf.reshape(patches[k,1,1,:],(512,512,3))"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# fig, (ax1, ax2) = plt.subplots(1, 2)\n","# ax1.imshow(imgs[0][0])\n","# ax2.imshow(imgs[1][0])\n","\n","\n","# plt_img_at_idx(0,0,0)\n","# plt_img_at_idx(0,0,1)\n","# plt_img_at_idx(0,0,2)\n","\n","# plt_img_at_idx(0,1,0)\n","# plt_img_at_idx(0,1,1)\n","# plt_img_at_idx(0,1,2)\n","\n","# plt_img_at_idx(0,2,0)\n","# plt_img_at_idx(0,2,1)\n","# plt_img_at_idx(0,2,2)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}