{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport sys","metadata":{"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# sys.path.append('../input/keras-segmentors/image-segmentation-keras-master')\nsys.path.append('../input/kerasdeeplabv3pluslatest/keras-deeplab-v3-plus-master')\n#!pip install --upgrade git+https://github.com/divamgupta/image-segmentation-keras","metadata":{"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\nimport os\nfrom tqdm import tqdm\nfrom tensorflow.keras.layers import Convolution2D,ZeroPadding2D,Conv2D,MaxPool2D,Dense,BatchNormalization,Dropout,Input,Activation,Flatten,Add,UpSampling2D,MaxPooling2D,Concatenate,AveragePooling2D\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.optimizers import Adam\nimport tensorflow_addons as tfa\nimport sys\nfrom multiprocessing.dummy import Pool as ThreadPool\nimport random\nimport numpy as np\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nimport tensorflow.keras.backend as K\nimport os\nimport time\nfrom skimage.transform import resize\nfrom tensorflow.keras.losses import binary_crossentropy\nfrom model import Deeplabv3\nfrom PIL import Image","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"code","source":"# Preparing a list of files from training dataset\n\n# Read list of images in a dataframe\nfilenames_inp=pd.DataFrame({\"file_names\":os.listdir(\"../input/massachusetts-roads-dataset/road_segmentation_ideal/training/input\")})\n\n# Read list of masks in a dataframe\nfilenames_output=pd.DataFrame({\"file_names\":os.listdir(\"../input/massachusetts-roads-dataset/road_segmentation_ideal/training/output\")})\n\n# Since all images do not have masks lets filter out those images\nfilenames=filenames_inp.loc[filenames_inp.file_names.isin(filenames_output[\"file_names\"]),:]","metadata":{"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Preparing a list of files from test dataset\n\n# Read list of images in a dataframe\nval_filenames_inp=pd.DataFrame({\"file_names\":os.listdir(\"../input/massachusetts-roads-dataset/road_segmentation_ideal/testing/input\")})\n\n# Read list of masks in a dataframe\nval_filenames_output=pd.DataFrame({\"file_names\":os.listdir(\"../input/massachusetts-roads-dataset/road_segmentation_ideal/testing/output\")})\n\n# Since all images do not have masks lets filter out those images\nval_filenames=val_filenames_inp.loc[val_filenames_inp.file_names.isin(val_filenames_output[\"file_names\"]),:]","metadata":{"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE=13\nNUM_PARALLEL_CALLS_DS=os.cpu_count()","metadata":{"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import backend as K\n# Creating the dataset\n\ndef get_image_data(image_name):\n    img = tf.io.read_file('../input/massachusetts-roads-dataset/road_segmentation_ideal/training/input/' + image_name)\n    msk = tf.io.read_file('../input/massachusetts-roads-dataset/road_segmentation_ideal/training/output/' + image_name)\n    img=tf.image.decode_png(img)\n    msk=tf.image.decode_png(msk)\n    return tf.cast(img,tf.float32)/255.,tf.cast(msk,tf.float32)/255.,image_name\n\ndef get_image_data_val(image_name):\n    img = tf.io.read_file('../input/massachusetts-roads-dataset/road_segmentation_ideal/testing/input/' + image_name)\n    msk = tf.io.read_file('../input/massachusetts-roads-dataset/road_segmentation_ideal/testing/output/' + image_name)\n    img=tf.image.decode_png(img)\n    msk=tf.image.decode_png(msk)\n    return tf.cast(img,tf.float32)/255.,tf.cast(msk,tf.float32)/255.,image_name\n\ndef get_datasets():\n    with tf.device('/cpu:0'):\n        train_data=tf.data.Dataset.from_tensor_slices(filenames['file_names']).shuffle(buffer_size=len(filenames)).map(get_image_data,num_parallel_calls=NUM_PARALLEL_CALLS_DS).batch(BATCH_SIZE,drop_remainder=False)\n        validation_data=tf.data.Dataset.from_tensor_slices(val_filenames['file_names']).map(get_image_data_val,num_parallel_calls=NUM_PARALLEL_CALLS_DS).batch(BATCH_SIZE,drop_remainder=False)\n    return train_data,validation_data","metadata":{"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Load the Model and Define the Metrics","metadata":{}},{"cell_type":"code","source":"def iou_fun(y_true, y_pred):\n    \"\"\"\n        This function calculates intersection over union\n    \"\"\"\n    num = K.sum(K.abs(y_true * tf.math.round(y_pred)))\n    den = K.sum(K.abs(tf.cast((y_true + tf.math.round(y_pred))!=0,tf.float32)))    \n    return num/den\n\n\n# Load model Deeplabv3\nmodel_final=Deeplabv3(input_shape=(512, 512, 3), classes=1,activation='sigmoid',backbone='xception')\n\n# Load weight of the trained model\nmodel_final.load_weights('../input/roaddetectiondeeplabv3-lr-512/model/model10.hdf5') ","metadata":{"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"!mkdir test_predictions","metadata":{"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory ‘test_predictions’: File exists\n","output_type":"stream"}]},{"cell_type":"code","source":"metric_lst=[]\n\nfor cutoff in tqdm([.1,.2,.3,.4,.5,.6,.7]):\n    iou_lst=[]\n    precision_lst=[]\n    recall_lst=[]\n    accuracy_lst=[]\n    _,validation_data=get_datasets()\n\n    for data in validation_data:        \n        patches=tf.image.extract_patches(data[0],\n                                             sizes=[1, 512, 512, 1],\n                                             strides=[1, 512, 512, 1],\n                                             rates=[1, 1, 1, 1],\n                                             padding='SAME')\n\n        patches=tf.reshape(patches,(data[0].shape[0]*9,512,512,3))\n        predictions=model_final.predict(patches)\n\n\n        for i in range(data[0].shape[0]):\n            prediction_res=np.zeros((512*3,512*3,1))       \n\n\n            prediction_res[512*0:512*1,512*0:512*1,:]=predictions[0+(i*9),:,:,:]        \n            prediction_res[512*0:512*1,512*1:512*2,:]=predictions[1+(i*9),:,:,:]\n            prediction_res[512*0:512*1,512*2:512*3,:]=predictions[2+(i*9),:,:,:]\n\n\n            prediction_res[512*1:512*2,512*0:512*1,:]=predictions[3+(i*9),:,:,:]\n            prediction_res[512*1:512*2,512*1:512*2,:]=predictions[4+(i*9),:,:,:]\n            prediction_res[512*1:512*2,512*2:512*3,:]=predictions[5+(i*9),:,:,:]\n\n\n            prediction_res[512*2:512*3,512*0:512*1,:]=predictions[6+(i*9),:,:,:]\n            prediction_res[512*2:512*3,512*1:512*2,:]=predictions[7+(i*9),:,:,:]\n            prediction_res[512*2:512*3,512*2:512*3,:]=predictions[8+(i*9),:,:,:]\n\n\n\n\n            result=tf.cast(prediction_res[18:-18,18:-18,:]>cutoff,tf.float32)               \n            result=result.numpy()\n\n\n\n            m = tf.keras.metrics.Precision()\n            m.update_state(data[1][i,:,:,:],result)\n            precision_lst.append(m.result().numpy())\n\n            m = tf.keras.metrics.Recall()\n            m.update_state(data[1][i,:,:,:],result)\n            recall_lst.append(m.result().numpy())\n\n            m = tf.keras.metrics.Accuracy()\n            m.update_state(data[1][i,:,:,:],result)\n            accuracy_lst.append(m.result().numpy()) \n\n            res_iou=iou_fun(data[1][i,:,:,:],result)  \n            iou_lst.append(res_iou)            \n            plt.show()\n    metric_lst.append([np.mean(iou_lst),np.mean(precision_lst),np.mean(recall_lst),np.mean(accuracy_lst)])    \n \n\nmetric_df=pd.DataFrame(metric_lst,index=['p1','p2','p3','p4','p5','p6','p7'],columns=['iou','precision','recall','accuracy'])\n\nmetric_df","metadata":{"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"100%|██████████| 7/7 [20:20<00:00, 174.32s/it]\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"         iou  precision    recall  accuracy\np1  0.531267   0.577087  0.872583  0.947554\np2  0.580988   0.666073  0.820519  0.959502\np3  0.596643   0.721319  0.775136  0.964006\np4  0.596556   0.763958  0.730564  0.966000\np5  0.584912   0.800355  0.683745  0.966575\np6  0.560681   0.833035  0.630520  0.965994\np7  0.520660   0.865307  0.565580  0.964178","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>iou</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>p1</th>\n      <td>0.531267</td>\n      <td>0.577087</td>\n      <td>0.872583</td>\n      <td>0.947554</td>\n    </tr>\n    <tr>\n      <th>p2</th>\n      <td>0.580988</td>\n      <td>0.666073</td>\n      <td>0.820519</td>\n      <td>0.959502</td>\n    </tr>\n    <tr>\n      <th>p3</th>\n      <td>0.596643</td>\n      <td>0.721319</td>\n      <td>0.775136</td>\n      <td>0.964006</td>\n    </tr>\n    <tr>\n      <th>p4</th>\n      <td>0.596556</td>\n      <td>0.763958</td>\n      <td>0.730564</td>\n      <td>0.966000</td>\n    </tr>\n    <tr>\n      <th>p5</th>\n      <td>0.584912</td>\n      <td>0.800355</td>\n      <td>0.683745</td>\n      <td>0.966575</td>\n    </tr>\n    <tr>\n      <th>p6</th>\n      <td>0.560681</td>\n      <td>0.833035</td>\n      <td>0.630520</td>\n      <td>0.965994</td>\n    </tr>\n    <tr>\n      <th>p7</th>\n      <td>0.520660</td>\n      <td>0.865307</td>\n      <td>0.565580</td>\n      <td>0.964178</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"<h1>Storing final predictions and Visualize at cutoff=0.4 :- </h1>","metadata":{}},{"cell_type":"code","source":"iou_lst=[]\nprecision_lst=[]\nrecall_lst=[]\naccuracy_lst=[]\n_,validation_data=get_datasets()\n\nfor data in validation_data:\n    print(data[0].shape)\n    patches=tf.image.extract_patches(data[0],\n                                         sizes=[1, 512, 512, 1],\n                                         strides=[1, 512, 512, 1],\n                                         rates=[1, 1, 1, 1],\n                                         padding='SAME')\n    \n    patches=tf.reshape(patches,(data[0].shape[0]*9,512,512,3))\n    predictions=model_final.predict(patches)\n    \n    for i in range(data[0].shape[0]):\n        prediction_res=np.zeros((512*3,512*3,1))       \n        \n        \n        prediction_res[512*0:512*1,512*0:512*1,:]=predictions[0+(i*9),:,:,:]        \n        prediction_res[512*0:512*1,512*1:512*2,:]=predictions[1+(i*9),:,:,:]\n        prediction_res[512*0:512*1,512*2:512*3,:]=predictions[2+(i*9),:,:,:]\n        \n        \n        prediction_res[512*1:512*2,512*0:512*1,:]=predictions[3+(i*9),:,:,:]\n        prediction_res[512*1:512*2,512*1:512*2,:]=predictions[4+(i*9),:,:,:]\n        prediction_res[512*1:512*2,512*2:512*3,:]=predictions[5+(i*9),:,:,:]\n        \n        \n        prediction_res[512*2:512*3,512*0:512*1,:]=predictions[6+(i*9),:,:,:]\n        prediction_res[512*2:512*3,512*1:512*2,:]=predictions[7+(i*9),:,:,:]\n        prediction_res[512*2:512*3,512*2:512*3,:]=predictions[8+(i*9),:,:,:]\n        \n\n\n        fig,(ax1,ax2,ax3)=plt.subplots(1,3,figsize=(15, 5))\n        ax1.imshow(data[0][i,:,:,:])\n        ax1.set_title('Image')\n        \n        ax2.imshow(data[1][i,:,:,:])\n        ax2.set_title('Label')\n        \n        result=tf.cast(prediction_res[18:-18,18:-18,:]>0.4,tf.float32)\n        ax3.imshow(result)\n        ax3.set_title('Predictions')\n        \n        result=result.numpy()\n        print(np.unique(result))\n        im = Image.fromarray(np.squeeze(result*255).astype(np.uint8))\n        im.save(\"./test_predictions/\" + data[2][i].numpy().decode('utf8'))\n        \n        \n        m = tf.keras.metrics.Precision()\n        m.update_state(data[1][i,:,:,:],result)\n        precision_lst.append(m.result().numpy())\n        \n        m = tf.keras.metrics.Recall()\n        m.update_state(data[1][i,:,:,:],result)\n        recall_lst.append(m.result().numpy())\n        \n        m = tf.keras.metrics.Accuracy()\n        m.update_state(data[1][i,:,:,:],result)\n        accuracy_lst.append(m.result().numpy()) \n        \n        res_iou=iou_fun(data[1][i,:,:,:],result)  \n        iou_lst.append(res_iou)\n        print('Till Mean IOU:',np.mean(iou_lst))\n        plt.show()\n        \nprint(\"Mean IOU:\",np.mean(iou_lst))\nprint(\"std IOU:\",np.std(iou_lst))\nprint(\"z IOU:\",np.mean(iou_lst)/np.std(iou_lst))\nprint(\"Mean Precision:\",np.mean(precision_lst))\nprint(\"Mean Recall:\",np.mean(recall_lst))\nprint(\"Mean Accuracy:\",np.mean(accuracy_lst))","metadata":{"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"(13, 1500, 1500, 3)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<h1>Visualization  of some predictions:-</h1>","metadata":{}},{"cell_type":"markdown","source":"<h2> Visualization For Cutoff=0.1</h2>","metadata":{}},{"cell_type":"code","source":"iou_lst=[]\n\n_,validation_data=get_datasets()\nfor data in iter(validation_data):\n    print(data[0].shape)\n    patches=tf.image.extract_patches(data[0],\n                                         sizes=[1, 512, 512, 1],\n                                         strides=[1, 512, 512, 1],\n                                         rates=[1, 1, 1, 1],\n                                         padding='SAME')\n    \n    patches=tf.reshape(patches,(data[0].shape[0]*9,512,512,3))\n    predictions=model_final.predict(patches)\n    \n    for i in range(data[0].shape[0]):\n        prediction_res=np.zeros((512*3,512*3,1))       \n        \n        \n        prediction_res[512*0:512*1,512*0:512*1,:]=predictions[0+(i*9),:,:,:]        \n        prediction_res[512*0:512*1,512*1:512*2,:]=predictions[1+(i*9),:,:,:]\n        prediction_res[512*0:512*1,512*2:512*3,:]=predictions[2+(i*9),:,:,:]\n        \n        \n        prediction_res[512*1:512*2,512*0:512*1,:]=predictions[3+(i*9),:,:,:]\n        prediction_res[512*1:512*2,512*1:512*2,:]=predictions[4+(i*9),:,:,:]\n        prediction_res[512*1:512*2,512*2:512*3,:]=predictions[5+(i*9),:,:,:]\n        \n        \n        prediction_res[512*2:512*3,512*0:512*1,:]=predictions[6+(i*9),:,:,:]\n        prediction_res[512*2:512*3,512*1:512*2,:]=predictions[7+(i*9),:,:,:]\n        prediction_res[512*2:512*3,512*2:512*3,:]=predictions[8+(i*9),:,:,:]\n        \n        \n        fig,(ax1,ax2,ax3)=plt.subplots(1,3,figsize=(15, 5))\n        ax1.imshow(data[0][i,:,:,:])\n        ax1.set_title('Image')\n        \n        ax2.imshow(data[1][i,:,:,:])\n        ax2.set_title('Label')\n        \n        result=tf.cast(prediction_res[18:-18,18:-18,:]>0.4,tf.float32)\n        ax3.imshow(result)\n        ax3.set_title('Predictions')                \n        \n        result=result.numpy()\n        print(np.unique(result))\n#         im = Image.fromarray(np.squeeze(result*255).astype(np.uint8))\n#         im.save(\"test_predictions/\" + data[2][i].numpy().decode('utf8'))\n        res_iou=iou_fun(data[1][i,:,:,:],result)        \n        iou_lst.append(res_iou)\n        print('Till Mean IOU:',np.mean(iou_lst))\n        plt.show()\nprint(\"Mean IOU:\",np.mean(iou_lst))\nprint(\"std IOU:\",np.std(iou_lst))\nprint(\"z IOU:\",np.mean(iou_lst)/np.std(iou_lst))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2> Visualization For Cutoff=0.2</h2>","metadata":{}},{"cell_type":"code","source":"iou_lst=[]\n_,validation_data=get_datasets()\nfor data in validation_data:\n    print(data[0].shape)\n    patches=tf.image.extract_patches(data[0],\n                                         sizes=[1, 512, 512, 1],\n                                         strides=[1, 512, 512, 1],\n                                         rates=[1, 1, 1, 1],\n                                         padding='SAME')\n    \n    patches=tf.reshape(patches,(data[0].shape[0]*9,512,512,3))\n    predictions=model_final.predict(patches)\n    \n    for i in range(data[0].shape[0]):\n        prediction_res=np.zeros((512*3,512*3,1))       \n        \n        \n        prediction_res[512*0:512*1,512*0:512*1,:]=predictions[0+(i*9),:,:,:]        \n        prediction_res[512*0:512*1,512*1:512*2,:]=predictions[1+(i*9),:,:,:]\n        prediction_res[512*0:512*1,512*2:512*3,:]=predictions[2+(i*9),:,:,:]\n        \n        \n        prediction_res[512*1:512*2,512*0:512*1,:]=predictions[3+(i*9),:,:,:]\n        prediction_res[512*1:512*2,512*1:512*2,:]=predictions[4+(i*9),:,:,:]\n        prediction_res[512*1:512*2,512*2:512*3,:]=predictions[5+(i*9),:,:,:]\n        \n        \n        prediction_res[512*2:512*3,512*0:512*1,:]=predictions[6+(i*9),:,:,:]\n        prediction_res[512*2:512*3,512*1:512*2,:]=predictions[7+(i*9),:,:,:]\n        prediction_res[512*2:512*3,512*2:512*3,:]=predictions[8+(i*9),:,:,:]\n        \n\n\n        fig,(ax1,ax2,ax3)=plt.subplots(1,3,figsize=(15, 5))\n        ax1.imshow(data[0][i,:,:,:])\n        ax1.set_title('Image')\n        \n        ax2.imshow(data[1][i,:,:,:])\n        ax2.set_title('Label')\n        \n        result=tf.cast(prediction_res[18:-18,18:-18,:]>0.4,tf.float32)\n        ax3.imshow(result)\n        ax3.set_title('Predictions')  \n        \n        result=result.numpy()\n        print(np.unique(result))\n#         im = Image.fromarray(np.squeeze(result*255).astype(np.uint8))\n#         im.save(\"test_predictions/\" + data[2][i].numpy().decode('utf8'))\n        res_iou=iou_fun(data[1][i,:,:,:],result)        \n        iou_lst.append(res_iou)\n        print('Till Mean IOU:',np.mean(iou_lst))\n        plt.show()\nprint(\"Mean IOU:\",np.mean(iou_lst))\nprint(\"std IOU:\",np.std(iou_lst))\nprint(\"z IOU:\",np.mean(iou_lst)/np.std(iou_lst))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2> Visualization For Cutoff=0.3</h2>","metadata":{}},{"cell_type":"code","source":"iou_lst=[]\n_,validation_data=get_datasets()\nfor data in validation_data:\n    print(data[0].shape)\n    patches=tf.image.extract_patches(data[0],\n                                         sizes=[1, 512, 512, 1],\n                                         strides=[1, 512, 512, 1],\n                                         rates=[1, 1, 1, 1],\n                                         padding='SAME')\n    \n    patches=tf.reshape(patches,(data[0].shape[0]*9,512,512,3))\n    predictions=model_final.predict(patches)\n    \n    for i in range(data[0].shape[0]):\n        prediction_res=np.zeros((512*3,512*3,1))       \n        \n        \n        prediction_res[512*0:512*1,512*0:512*1,:]=predictions[0+(i*9),:,:,:]        \n        prediction_res[512*0:512*1,512*1:512*2,:]=predictions[1+(i*9),:,:,:]\n        prediction_res[512*0:512*1,512*2:512*3,:]=predictions[2+(i*9),:,:,:]\n        \n        \n        prediction_res[512*1:512*2,512*0:512*1,:]=predictions[3+(i*9),:,:,:]\n        prediction_res[512*1:512*2,512*1:512*2,:]=predictions[4+(i*9),:,:,:]\n        prediction_res[512*1:512*2,512*2:512*3,:]=predictions[5+(i*9),:,:,:]\n        \n        \n        prediction_res[512*2:512*3,512*0:512*1,:]=predictions[6+(i*9),:,:,:]\n        prediction_res[512*2:512*3,512*1:512*2,:]=predictions[7+(i*9),:,:,:]\n        prediction_res[512*2:512*3,512*2:512*3,:]=predictions[8+(i*9),:,:,:]\n        \n\n\n        fig,(ax1,ax2,ax3)=plt.subplots(1,3,figsize=(15, 5))\n        ax1.imshow(data[0][i,:,:,:])\n        ax1.set_title('Image')\n        \n        ax2.imshow(data[1][i,:,:,:])\n        ax2.set_title('Label')\n        \n        result=tf.cast(prediction_res[18:-18,18:-18,:]>0.4,tf.float32)\n        ax3.imshow(result)\n        ax3.set_title('Predictions')  \n        \n        result=result.numpy()\n        print(np.unique(result))\n#         im = Image.fromarray(np.squeeze(result*255).astype(np.uint8))\n#         im.save(\"test_predictions/\" + data[2][i].numpy().decode('utf8'))\n        res_iou=iou_fun(data[1][i,:,:,:],result)        \n        iou_lst.append(res_iou)\n        print('Till Mean IOU:',np.mean(iou_lst))\n        plt.show()\nprint(\"Mean IOU:\",np.mean(iou_lst))\nprint(\"std IOU:\",np.std(iou_lst))\nprint(\"z IOU:\",np.mean(iou_lst)/np.std(iou_lst))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2> Visualization For Cutoff=0.5</h2>","metadata":{}},{"cell_type":"code","source":"iou_lst=[]\n_,validation_data=get_datasets()\n\nfor data in validation_data:\n    print(data[0].shape)\n    patches=tf.image.extract_patches(data[0],\n                                         sizes=[1, 512, 512, 1],\n                                         strides=[1, 512, 512, 1],\n                                         rates=[1, 1, 1, 1],\n                                         padding='SAME')\n    \n    patches=tf.reshape(patches,(data[0].shape[0]*9,512,512,3))\n    predictions=model_final.predict(patches)\n    \n    for i in range(data[0].shape[0]):\n        prediction_res=np.zeros((512*3,512*3,1))       \n        \n        \n        prediction_res[512*0:512*1,512*0:512*1,:]=predictions[0+(i*9),:,:,:]        \n        prediction_res[512*0:512*1,512*1:512*2,:]=predictions[1+(i*9),:,:,:]\n        prediction_res[512*0:512*1,512*2:512*3,:]=predictions[2+(i*9),:,:,:]\n        \n        \n        prediction_res[512*1:512*2,512*0:512*1,:]=predictions[3+(i*9),:,:,:]\n        prediction_res[512*1:512*2,512*1:512*2,:]=predictions[4+(i*9),:,:,:]\n        prediction_res[512*1:512*2,512*2:512*3,:]=predictions[5+(i*9),:,:,:]\n        \n        \n        prediction_res[512*2:512*3,512*0:512*1,:]=predictions[6+(i*9),:,:,:]\n        prediction_res[512*2:512*3,512*1:512*2,:]=predictions[7+(i*9),:,:,:]\n        prediction_res[512*2:512*3,512*2:512*3,:]=predictions[8+(i*9),:,:,:]\n        \n\n\n        fig,(ax1,ax2,ax3)=plt.subplots(1,3,figsize=(15, 5))\n        ax1.imshow(data[0][i,:,:,:])\n        ax1.set_title('Image')\n        \n        ax2.imshow(data[1][i,:,:,:])\n        ax2.set_title('Label')\n        \n        result=tf.cast(prediction_res[18:-18,18:-18,:]>0.4,tf.float32)\n        ax3.imshow(result)\n        ax3.set_title('Predictions')  \n        \n        result=result.numpy()\n        print(np.unique(result))\n#         im = Image.fromarray(np.squeeze(result*255).astype(np.uint8))\n#         im.save(\"test_predictions/\" + data[2][i].numpy().decode('utf8'))\n        res_iou=iou_fun(data[1][i,:,:,:],result)        \n        iou_lst.append(res_iou)\n        print('Till Mean IOU:',np.mean(iou_lst))\n        plt.show()\nprint(\"Mean IOU:\",np.mean(iou_lst))\nprint(\"std IOU:\",np.std(iou_lst))\nprint(\"z IOU:\",np.mean(iou_lst)/np.std(iou_lst))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}